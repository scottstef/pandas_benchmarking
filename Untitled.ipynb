{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43472955-9964-41fe-8095-cc2da5ba08cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b55c133-3389-4ae9-80ac-1c3d35e82ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Run 1 ===\n",
      "Running with count=100 million rows and num_cols=20 columns\n",
      "\n",
      "Generating fake data with pandas...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "csv_path = '/home/sstefanoski/repos/code/crunch_tests/big_fake_data.csv'\n",
    "db_path = '/home/sstefanoski/repos/code/crunch_tests/benchmark_results.db'\n",
    "benchmark_results = []\n",
    "\n",
    "# Function to generate data\n",
    "def generate_data(count, num_cols):\n",
    "    NUM_ROWS = count * 1_000_000  # 1 million rows per \"count\"\n",
    "    NUM_COLS = num_cols\n",
    "\n",
    "    print(\"\\nGenerating fake data with pandas...\")\n",
    "    data = np.random.rand(NUM_ROWS, NUM_COLS)\n",
    "    columns = [f'col_{i}' for i in range(NUM_COLS)]\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    # Save to CSV using Pandas\n",
    "    print('Starting to write file')\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print('Done writing to file')\n",
    "\n",
    "    file_stats = os.stat(csv_path)\n",
    "    file_size_mb = file_stats.st_size / (1024 * 1024)  # File size in MB\n",
    "    print(f'File Size in MegaBytes is {file_size_mb:.2f}')\n",
    "    return file_size_mb  \n",
    "\n",
    "# Benchmark using Pandas\n",
    "def pandas_benchmark():\n",
    "    print(\"\\n=== Pandas Benchmark ===\")\n",
    "    start = time.time()\n",
    "\n",
    "    df_pandas = pd.read_csv(csv_path)\n",
    "    result_pandas = df_pandas.groupby('col_0').mean()\n",
    "\n",
    "    end = time.time()\n",
    "    pandas_time = end - start\n",
    "    print(f\"Pandas time: {pandas_time:.2f} seconds\")\n",
    "    benchmark_results.append(('Pandas', pandas_time))\n",
    "\n",
    "    del df_pandas\n",
    "    del result_pandas\n",
    "    return pandas_time\n",
    "\n",
    "# Benchmark using Dask\n",
    "def dask_benchmark():\n",
    "    print(\"\\n=== Dask Benchmark ===\")\n",
    "    start = time.time()\n",
    "\n",
    "    df_dask = dd.read_csv(csv_path)\n",
    "    result_dask = df_dask.groupby('col_0').mean().compute()\n",
    "\n",
    "    end = time.time()\n",
    "    dask_time = end - start\n",
    "    print(f\"Dask time: {dask_time:.2f} seconds\")\n",
    "    benchmark_results.append(('Dask', dask_time))\n",
    "\n",
    "    del df_dask\n",
    "    del result_dask\n",
    "    return dask_time\n",
    "\n",
    "# Native Python Benchmark (mean calculation with native Python)\n",
    "def native_python_benchmark():\n",
    "    print(\"\\n=== Native Python Benchmark ===\")\n",
    "    start = time.time()\n",
    "\n",
    "    # Read the CSV file using Python's built-in csv module\n",
    "    with open(csv_path, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        headers = next(reader)  # Skip header row\n",
    "        col_0 = [float(row[0]) for row in reader]\n",
    "        col_1 = [float(row[1]) for row in reader]  # Assuming another column for the mean calculation\n",
    "\n",
    "    # Group by col_0 and calculate the mean for col_1 (simulating groupby in pandas/dask)\n",
    "    grouped_data = {}\n",
    "    for value, col_1_val in zip(col_0, col_1):\n",
    "        if value not in grouped_data:\n",
    "            grouped_data[value] = []\n",
    "        grouped_data[value].append(col_1_val)\n",
    "\n",
    "    # Calculate the mean of each group\n",
    "    means = {key: sum(values) / len(values) for key, values in grouped_data.items()}\n",
    "\n",
    "    end = time.time()\n",
    "    native_python_time = end - start\n",
    "    print(f\"Native Python time: {native_python_time:.2f} seconds\")\n",
    "    benchmark_results.append(('Native Python', native_python_time))\n",
    "\n",
    "    return native_python_time\n",
    "\n",
    "\n",
    "# Initialize the database\n",
    "def initialize_database():\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    c.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS benchmarks (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            run_date TEXT,\n",
    "            count INTEGER,\n",
    "            num_cols INTEGER,\n",
    "            file_size_mb REAL,\n",
    "            pandas_time REAL,\n",
    "            dask_time REAL,\n",
    "            native_python_time REAL\n",
    "        )\n",
    "    ''')\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "# Save benchmark results into the database\n",
    "def save_results(run_date, count, num_cols, file_size_mb, pandas_time, dask_time, native_python_time):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    c.execute('''\n",
    "        INSERT INTO benchmarks (run_date, count, num_cols, file_size_mb, pandas_time, dask_time, native_python_time)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "    ''', (run_date, count, num_cols, file_size_mb, pandas_time, dask_time, native_python_time))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "# Plot the benchmark results\n",
    "def plot_benchmarks():\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    plot_file_name = f\"benchmark_results_{timestamp}.png\"\n",
    "\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    df = pd.read_sql_query(\"SELECT * FROM benchmarks\", conn)\n",
    "    conn.close()\n",
    "\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.plot(df['run_date'], df['pandas_time'], label='Pandas', marker='o')\n",
    "    plt.plot(df['run_date'], df['dask_time'], label='Dask', marker='o')\n",
    "    plt.plot(df['run_date'], df['native_python_time'], label='Native Python', marker='o')\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        annotation = f\"{row['count']}M, {row['num_cols']} cols\"\n",
    "        plt.annotate(annotation, (row['run_date'], row['pandas_time']),\n",
    "                     textcoords=\"offset points\", xytext=(0,10), ha='center', fontsize=8, color='green')\n",
    "        plt.annotate(annotation, (row['run_date'], row['dask_time']),\n",
    "                     textcoords=\"offset points\", xytext=(0,-15), ha='center', fontsize=8, color='blue')\n",
    "        plt.annotate(annotation, (row['run_date'], row['native_python_time']),\n",
    "                     textcoords=\"offset points\", xytext=(0,-30), ha='center', fontsize=8, color='red')\n",
    "\n",
    "    plt.xlabel('Run Date')\n",
    "    plt.ylabel('Time (seconds)')\n",
    "\n",
    "    last_run = df['run_date'].max()\n",
    "    total_runs = len(df)\n",
    "    plt.title(f'Benchmark Performance Over Time\\n{total_runs} Runs â€¢ Last Test: {last_run}', fontsize=16)\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    timestamp_now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    plt.text(1.0, -0.15, f\"Plot generated: {timestamp_now}\",\n",
    "             ha='right', va='center', transform=plt.gca().transAxes, fontsize=8, color='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(images/plot_file_name, dpi=300)\n",
    "    print(f\"Plot saved as {plot_file_name}.\")\n",
    "\n",
    "    plt.show(block=False)\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    initialize_database()\n",
    "\n",
    "    seed_value = int(time.time())  # Using current time as a dynamic seed for randomness\n",
    "    random.seed(seed_value)        # Seed the random module\n",
    "    np.random.seed(seed_value)\n",
    "\n",
    "    for i in range(1):  # Run 20 tests\n",
    "        print(f\"\\n=== Run {i+1} ===\")\n",
    "\n",
    "        count = 100 #random.randint(10, 30)  # Randomly choose a count (number of millions of rows)\n",
    "        num_cols = 20 #random.randint(6, 40)  # Randomly choose the number of columns\n",
    "\n",
    "        print(f\"Running with count={count} million rows and num_cols={num_cols} columns\")\n",
    "\n",
    "        file_size_mb = generate_data(count, num_cols)\n",
    "\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5631caf4-076e-495b-ac4d-d9ddfd727292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The source is yoda\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "source = socket.getfqdn()\n",
    "print(f'The source is {source}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001a4207-a038-4fb3-9bc5-81ea679f0de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
